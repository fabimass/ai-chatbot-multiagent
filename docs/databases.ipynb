{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Databases - Research\n",
    "\n",
    "Vector search is a cutting-edge approach to searching and retrieving data that leverages the power of vector similarity calculations. Unlike traditional keyword-based search, which matches documents based on the occurrence of specific terms, vector search focuses on the semantic meaning and similarity of data points. By representing data as vectors in a high-dimensional space, vector search enables more accurate and intuitive search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv==1.0.1 langchain==0.2.1 langchain-community==0.2.1 scikit-learn==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load a document. Let's try with a pdf and a markdown file.\n",
    "\n",
    "Then, we will split it into smaller chunks of text. This serves several important purposes:\n",
    "- Granularity: By splitting a document into smaller chunks, you can retrieve more specific and relevant pieces of information. If you work with large documents as single chunks, retrieval can become inefficient and less precise.\n",
    "- Search Performance: Smaller chunks improve the performance of search algorithms. It's easier to match a query against smaller, more focused pieces of text rather than a large document.\n",
    "- Computational efficiency: Working with entire documents as single units can be memory-expensive and slow. Splitting documents into chunks allows for more efficient use of memory and computational resources.\n",
    "\n",
    "Practical example: Imagine we have a large document, such as a product manual or a scientific paper. If a user asks a question like \"How do I reset the device?\" or \"What is the conclusion of the study?\", splitting the document into smaller chunks allows the chatbot to:\n",
    "- Efficiently locate and retrieve the most relevant section about device resetting instructions or the conclusion of the study.\n",
    "- Avoid returning irrelevant parts of the document, which might confuse the user.\n",
    "- Provide a faster response by only processing a small portion of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypdf==4.2.0 unstructured==0.14.7 markdown==3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define how the text should be split:\n",
    "#  - Each chunk should be up to 512 characters long.\n",
    "#  - There should be an overlap of 64 characters between consecutive chunks. \n",
    "#  - This overlap helps maintain context across the chunks.\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 311\n",
      "page_content='GENERATIVE AI: HYPE,  OR \\nTRUL\\nY TRANSFORMATIVE?ISSUE 120 | July 5, 2023 | 12:28 PM EDT”\\x01\\x01\\x01\\x01\\x01P\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01 \\x01\\x01 \\x01 \\x01Global Macro  \\nResearch\\nInvestors should consider this report as only a single factor in making their investment decision. For \\nReg AC certiﬁcation and other important disclosures, see the Disclosure Appendix, or go to www.gs.com/research/hedge.html.\\nThe Goldman Sachs Group, Inc.Since the release of OpenAI’s generative AI tool ChatGPT in November, investor' metadata={'source': 'example_data/example_pdf.pdf', 'page': 0}\n",
      "page_content='interest in generative AI technology has surged. The disruptive potential of  this technology, and whether the hype around it—and market pricing—has gone too far, is Top of Mind. We speak with Conviction’s Sarah Guo, NYU’s Gary Marcus, and GS GIR’s US software and internet analysts Kash Rangan and Eric Sheridan about what the technology can—and can’t—do at this stage. GS economists then assess the technology’s potentially large impact on productivity and growth, which our equity strategists estimate could' metadata={'source': 'example_data/example_pdf.pdf', 'page': 0}\n",
      "page_content='and growth, which our equity strategists estimate could translate into signiﬁcant upside for US equities over the medium-to-longer term, though our strategists also warn that past productivity' metadata={'source': 'example_data/example_pdf.pdf', 'page': 0}\n",
      "page_content='booms have resulted in equity bubbles that ultimately burst. We also discuss where the most compelling investment opportunities in the AI space may lie today, and the near-term risks investors should most watch out for.        \\n““ INTERVIEWS WITH:  \\nSarah Guo, Founder, Conviction, former General Partner, Greylock \\nGary Marcus, Professor Emeritus of Psychology and Neural Science, \\nNew York University \\nKash Rangan, US Software Equity Research Analyst, Goldman Sachs;' metadata={'source': 'example_data/example_pdf.pdf', 'page': 0}\n",
      "page_content='Eric Sheridan, US Internet Equity Research Analyst, Goldman Sachs  \\nAI’S POTENTIALLY LARGE ECONOMIC IMPACTS \\nJoseph Briggs, GS Global Economics Research \\nUS EQUITIES: GAUGING THE AI UPSIDE \\nRyan Hammond and David Kostin, GS US Portfolio Strategy Research \\nMARKETS AROUND PAST PRODUCTIVITY BOOMS \\nDominic Wilson and Vickie Chang, GS Markets Research \\nWHAT WE’RE HEARING FROM PUBLIC INVESTORS \\nPeter Callahan, GS Global Banking & Markets WHAT’S INSIDEof\\nAllison Nathan | allison.nathan@gs.com       ...AND MORE' metadata={'source': 'example_data/example_pdf.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# PDF\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(\"example_data/example_pdf.pdf\")\n",
    "\n",
    "# Load pdf and split into chunks.\n",
    "pdf_chunks = pdf_loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# Get the number of chunks\n",
    "print(f\"Number of chunks: {len(pdf_chunks)}\")\n",
    "\n",
    "# Print the first 5 chunks\n",
    "for chunk in pdf_chunks[:5]:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 7\n",
      "page_content='The Football World Cup\\n\\nThe FIFA World Cup, often simply referred to as the World Cup, is the premier international football competition. Organized by the Fédération Internationale de Football Association (FIFA), it features national teams from around the globe competing for the most coveted trophy in the sport. The tournament is held every four years and is one of the most widely viewed and followed sporting events in the world.\\n\\nHistory' metadata={'source': 'example_data/example_markdown.md'}\n",
      "page_content='History\\n\\nThe first World Cup was held in 1930 in Uruguay, with the host nation emerging as the champions. Since then, the tournament has grown significantly in size and popularity. Originally featuring just 13 teams, the World Cup now includes 32 teams in the final tournament, with plans to expand to 48 teams in the near future.\\n\\nFormat\\n\\nThe World Cup is divided into two main stages:' metadata={'source': 'example_data/example_markdown.md'}\n",
      "page_content='Format\\n\\nThe World Cup is divided into two main stages:\\n\\nQualification: This stage occurs over the three years preceding the tournament, with national teams competing within their respective confederations (e.g., UEFA, CONMEBOL, AFC) to secure a spot in the finals.\\n\\nFinal Tournament: Held over approximately one month, the final tournament features:' metadata={'source': 'example_data/example_markdown.md'}\n",
      "page_content='Group Stage: Teams are divided into eight groups of four. Each team plays three matches in a round-robin format. The top two teams from each group advance to the knockout stage.\\n\\nKnockout Stage: A single-elimination format, starting with the Round of 16 and culminating in the final match. This stage includes the Round of 16, Quarter-Finals, Semi-Finals, and the Final.\\n\\nNotable Moments\\n\\nThe World Cup has produced countless memorable moments, including:' metadata={'source': 'example_data/example_markdown.md'}\n",
      "page_content=\"Maracanazo (1950): Uruguay's shocking victory over Brazil in the final match at the Maracanã Stadium.\\n\\nHand of God (1986): Diego Maradona's controversial goal against England in the quarter-finals.\\n\\nGermany 7, Brazil 1 (2014): Germany's stunning semi-final victory over host Brazil.\\n\\nRecords and Statistics\\n\\nMost Titles: Brazil holds the record with five World Cup victories.\\n\\nTop Scorer: Miroslav Klose of Germany is the top scorer in World Cup history with 16 goals.\" metadata={'source': 'example_data/example_markdown.md'}\n"
     ]
    }
   ],
   "source": [
    "# Markdown\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "md_loader = UnstructuredMarkdownLoader(\"example_data/example_markdown.md\")\n",
    "\n",
    "# Load pdf and split into chunks.\n",
    "md_chunks = md_loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# Get the number of chunks\n",
    "print(f\"Number of chunks: {len(md_chunks)}\")\n",
    "\n",
    "# Print the first 5 chunks\n",
    "for chunk in md_chunks[:5]:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will proceed to transform our text junks into vector embeddings.\n",
    "\n",
    "Vector embeddings is a powerful technique for transforming complex data into numerical forms that can be easily processed and analyzed by machine learning algorithms. It basically allows us to take virtually any data type and represent it as vectors.\n",
    "\n",
    "But it isn't as simple as just turning data into vectors. We want to ensure that we can perform tasks on this transformed data without losing the data's original meaning. For example, if we want to compare two sentences, we don't want just to compare the words they contain but rather whether or not they mean the same thing. \n",
    "\n",
    "To preserve the data's meaning, we need to understand how to produce vectors where relationships between the vectors make sense. To do this, we need what's known as an embedding model. We apply a pre-trained machine learning model that will produce a representation of this data that is more compact while preserving what's meaningful about the data.\n",
    "\n",
    "The goal of embeddings is to capture the semantic meaning or relationships between data points in a way that similar items are close together in the vector space, and dissimilar items are far apart. For example, consider two words \"king\" and \"queen\". An embedding might map these words to vectors such that the difference between the \"king\" and \"queen\" vectors is similar to the difference between the \"man\" and \"woman\" vectors. This reflects the underlying semantic relationships.\n",
    "\n",
    "Key characteristics of embeddings:\n",
    "- Dimensionality: The number of elements in the vector. Higher dimensions can capture more complex relationships but are computationally more expensive.\n",
    "- Similarity: Measured using metrics like cosine similarity or euclidean distance, which help in finding how close or far two vectors are from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between vectors.\n",
    "# Values close to 1 indicate very similar vectors, while values close to 0 indicate very different vectors.\n",
    "# Cosine similarity is particularly useful when the magnitude of the vectors is not as important as their direction. \n",
    "# It is often used in text analysis and information retrieval where the orientation (semantic meaning) of vectors \n",
    "# matters more than their magnitude.\n",
    "def compare_embeddings(vector_1, vector_2):\n",
    "    similarity = cosine_similarity([vector_1], [vector_2])\n",
    "    print(f\"Cosine similarity: {similarity[0][0]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sentences to test different embedding models\n",
    "sentences_list = [\n",
    "    # Include the same words but have different semantics. Similarity should be low.\n",
    "    [\"I want a new watch for my birthday\", \"I like to watch the TV on weekends\"],      \n",
    "    [\"The bank will close at 5 PM\", \"The river bank is a great place to relax\"],\n",
    "    # Convey the same meaning without sharing words. Similarity should be high.\n",
    "    [\"I have to go to the mechanic\", \"My car is broken\"], \n",
    "    [\"She went to the store to buy some groceries\", \"She went shopping for food\"],\n",
    "    # Completely unrelated in terms of their content and context. Similarity should be low.\n",
    "    [\"The stock market experienced a significant decline last week\", \"She enjoys painting landscapes in her free time\"],\n",
    "    [\"The sun rises in the east every morning\", \"Pizza is a popular food in Italy\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test an embedding model applying it to a set of sentences and analyzing similarity\n",
    "def test_embeddings(model):\n",
    "    for sentences_pair in sentences_list:\n",
    "        vector_1 = model.embed_query(sentences_pair[0])\n",
    "        print(f\"\\\"{sentences_pair[0]}\\\"\")\n",
    "        print(f\" Dimensionality: {len(vector_1)}\")\n",
    "        print(f\" Sample: {vector_1[:5]}\")\n",
    "        print()\n",
    "        \n",
    "        vector_2 = model.embed_query(sentences_pair[1])\n",
    "        print(f\"\\\"{sentences_pair[1]}\\\"\")\n",
    "        print(f\" Dimensionality: {len(vector_2)}\")\n",
    "        print(f\" Sample: {vector_2[:5]}\")\n",
    "        print()\n",
    "\n",
    "        compare_embeddings(vector_1, vector_2)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I want a new watch for my birthday.\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.0089229391887784, -0.05183125287294388, -0.06784740835428238, -0.04327891394495964, 0.04272729903459549]\n",
      "\n",
      "\"I like to watch the TV on weekends.\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.02537923865020275, -0.02598225325345993, -0.058093760162591934, 0.009168527089059353, 0.008474522270262241]\n",
      "\n",
      "Cosine similarity: 0.6764325794481864\n",
      "---\n",
      "\"The bank will close at 5 PM.\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.022659489884972572, 0.01701500453054905, -0.016876468434929848, -0.05867573246359825, 0.029572682455182076]\n",
      "\n",
      "\"The river bank is a great place to relax.\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.02937248907983303, -0.0046739946119487286, -0.015860099345445633, -0.02378806844353676, 0.0422411672770977]\n",
      "\n",
      "Cosine similarity: 0.6503056535628654\n",
      "---\n",
      "\"I have to go to the mechanic.\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.01886001229286194, -0.04712492972612381, -0.04557660594582558, -0.0175259280949831, -0.01612073928117752]\n",
      "\n",
      "\"My car is broken.\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.01076989620923996, -0.0006287064752541482, -0.04222916439175606, -0.03937700390815735, -0.017334243282675743]\n",
      "\n",
      "Cosine similarity: 0.8467823891644309\n",
      "---\n",
      "\"She went to the store to buy some groceries.\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.01256793737411499, -0.03262053802609444, -0.004737658891826868, -0.01143628265708685, 0.026368319988250732]\n",
      "\n",
      "\"She went shopping for food.\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.01306942943483591, -0.03148755431175232, -0.0216109286993742, -0.016208866611123085, 0.03499913588166237]\n",
      "\n",
      "Cosine similarity: 0.9491082947647929\n",
      "---\n",
      "\"The stock market experienced a significant decline last week.\"\n",
      " Dimensionality: 768\n",
      " Sample: [8.85653844306944e-06, -0.006838534958660603, 0.013232228346168995, 0.019059104844927788, 0.037991177290678024]\n",
      "\n",
      "\"She enjoys painting landscapes in her free time.\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.05429729074239731, -0.006333737168461084, -0.007246118038892746, -0.043314795941114426, 0.03419230505824089]\n",
      "\n",
      "Cosine similarity: 0.5190259994608787\n",
      "---\n",
      "\"The sun rises in the east every morning.\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.0076747159473598, 0.01138612162321806, -0.034804463386535645, -0.01935373991727829, 0.0143641522154212]\n",
      "\n",
      "\"Pizza is a popular food in Italy.\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.00506745046004653, -0.024209560826420784, 0.007711388170719147, 0.0022743651643395424, 0.025350229814648628]\n",
      "\n",
      "Cosine similarity: 0.5925884763648555\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "google_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "test_embeddings(google_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_huggingface==0.0.3 huggingface_hub==0.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I want a new watch for my birthday\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.043364789336919785, 0.04182625934481621, -0.0038558896631002426, 0.0431031733751297, 0.01737719029188156]\n",
      "\n",
      "\"I like to watch the TV on weekends\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.04785402491688728, 0.0326734222471714, 0.0009588559623807669, -0.0176838506013155, -0.03530512750148773]\n",
      "\n",
      "Cosine similarity: 0.176958964124023\n",
      "---\n",
      "\"The bank will close at 5 PM\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.04836975410580635, 0.0051988218910992146, -0.029005667194724083, 0.00420030765235424, 0.03131011128425598]\n",
      "\n",
      "\"The river bank is a great place to relax\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.08330544829368591, -0.014301057904958725, -0.029551850631833076, -0.00013575299817603081, -0.01434556394815445]\n",
      "\n",
      "Cosine similarity: 0.23080635655292628\n",
      "---\n",
      "\"I have to go to the mechanic\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.023156633600592613, -0.02565646730363369, -0.012464101426303387, 0.03722125664353371, -0.024508243426680565]\n",
      "\n",
      "\"My car is broken\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.03207498416304588, 0.04779843986034393, -0.025276659056544304, 0.05088168382644653, -0.005267248954623938]\n",
      "\n",
      "Cosine similarity: 0.6053909778607385\n",
      "---\n",
      "\"She went to the store to buy some groceries\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.01857244223356247, 0.02941843494772911, -0.008194404654204845, -0.030242005363106728, 0.04293426126241684]\n",
      "\n",
      "\"She went shopping for food\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.004079811740666628, 0.02301056496798992, -0.019069848582148552, -0.011250101961195469, 0.05938548222184181]\n",
      "\n",
      "Cosine similarity: 0.8859714537130734\n",
      "---\n",
      "\"The stock market experienced a significant decline last week\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.06019498035311699, 0.0500253289937973, -0.04552822932600975, -0.025974158197641373, 0.018337182700634003]\n",
      "\n",
      "\"She enjoys painting landscapes in her free time\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.0283308457583189, 0.05374739691615105, -0.028162294998764992, 0.027542121708393097, 0.007920113392174244]\n",
      "\n",
      "Cosine similarity: -0.09596994000259941\n",
      "---\n",
      "\"The sun rises in the east every morning\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.017762789502739906, 0.04152734950184822, 0.00964907743036747, -0.011952653527259827, -0.023875022307038307]\n",
      "\n",
      "\"Pizza is a popular food in Italy\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.014318383298814297, 0.07531707733869553, -0.014243819750845432, 0.01029131468385458, 0.02050625905394554]\n",
      "\n",
      "Cosine similarity: 0.1744469439305314\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "hface_embeddings = HuggingFaceEndpointEmbeddings()\n",
    "\n",
    "test_embeddings(hface_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding model | Sentence 1 | Sentence 2 | Cosine similarity \n",
    ":---: | :---: | :---: | :---:\n",
    "Google | \"I want a new watch for my birthday\" | \"I like to watch the TV on weekends\" | 0.67\n",
    "Google | \"The bank will close at 5 PM\" | \"The river bank is a great place to relax\" | 0.65\n",
    "Google | \"I have to go to the mechanic\" | \"My car is broken\" | 0.84\n",
    "Google | \"She went to the store to buy some groceries\" | \"She went shopping for food\" | 0.95\n",
    "Google | \"The stock market experienced a significant decline last week\" | \"She enjoys painting landscapes in her free time\" | 0.52\n",
    "Google | \"The sun rises in the east every morning\" | \"Pizza is a popular food in Italy\" | 0.59\n",
    "Hugging Face | \"I want a new watch for my birthday\" | \"I like to watch the TV on weekends\" | 0.17\n",
    "Hugging Face | \"The bank will close at 5 PM\" | \"The river bank is a great place to relax\" | 0.23\n",
    "Hugging Face | \"I have to go to the mechanic\" | \"My car is broken\" | 0.60\n",
    "Hugging Face | \"She went to the store to buy some groceries\" | \"She went shopping for food\" | 0.88\n",
    "Hugging Face | \"The stock market experienced a significant decline last week\" | \"She enjoys painting landscapes in her free time\" | -0.09\n",
    "Hugging Face | \"The sun rises in the east every morning\" | \"Pizza is a popular food in Italy\" | 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Google embedding model generally shows moderate to high cosine similarity scores for semantically related sentences. For example:\n",
    "  - \"I have to go to the mechanic\" and \"My car is broken\" (0.84) suggests good recognition of related topics.\n",
    "  - \"She went to the store to buy some groceries\" and \"She went shopping for food\" (0.95) indicates strong similarity in meaning.\n",
    "\n",
    "- The Hugging Face embedding model shows more varied cosine similarity scores across sentence pairs:\n",
    "  - While \"I have to go to the mechanic\" and \"My car is broken\" (0.60) are somewhat related, they show a lower score compared to Google's model.\n",
    "  - \"She went to the store to buy some groceries\" and \"She went shopping for food\" (0.88) shows higher similarity, but not as high as Google's score (0.95).\n",
    "\n",
    "Both embedding models generally perform well with semantically related sentences, although the Google model tends to exhibit higher similarity scores overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection with the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Astra DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using Datastax Astra DB:\n",
    "- Create a database in https://astra.datastax.com/\n",
    "- Obtain your database API endpoint, located under Database Details > API Endpoint, and save it as an environment variable called: ASTRA_DB_API_ENDPOINT\n",
    "- Generate a token and save it as an environment variable called: ASTRA_DB_APPLICATION_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-astradb==0.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_astradb import AstraDBVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vstore = AstraDBVectorStore(\n",
    "    embedding=google_embeddings,\n",
    "    collection_name=\"vector_db_test\", \n",
    "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
    "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
