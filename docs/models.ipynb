{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research on Large Language Models\n",
    "\n",
    "This investigation evaluates multiple large language models (LLMs) to determine their effectiveness for a retrieval-augmented generation (RAG) application. We assessed models including FLAN, BLOOM, Mistral 7B, GPT-4o, and Gemini Pro based on their accuracy, content generation capabilities, and response quality. The aim is to identify the model that best meets our requirements for precise and engaging outputs in a RAG context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv==1.0.1 langchain==0.2.1 langchain-community==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"who won the FIFA World Cup in the year 1998?\", \n",
    "             \"what is the capital of Jamaica?\", \n",
    "             \"who is the lead singer in Aerosmith?\",\n",
    "             \"how many NBA titles did Michael Jordan win?\",\n",
    "             \"write me a four line poem about computers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_test(llm, prompt_list):\n",
    "    print(\"-----\")\n",
    "    for prompt in prompt_list:\n",
    "        print(f\"{prompt}\\n {llm.predict(prompt)}\\n\")\n",
    "        print(\"-----\")\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face\n",
    "\n",
    "Hugging Face is a company and open-source community known for its contributions to natural language processing (NLP) and machine learning. It provides a platform that hosts a vast collection of pre-trained models, datasets, and tools, making it easier for developers and researchers to implement state-of-the-art AI in their projects.\n",
    "\n",
    "For using Hugging Face:\n",
    "  * Create an access token here: https://huggingface.co/settings/tokens\n",
    "  * Create an environment variable called: HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-huggingface==0.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain_huggingface.llms import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLAN\n",
    "\n",
    "- https://huggingface.co/google/flan-t5-large\n",
    "\n",
    "Flan-T5 is an open-source LLM that’s available for commercial usage. Published by Google researchers, Flan-T5 is an encoder-decoder model pre-trained on a variety of language tasks. The model has been trained on supervised and unsupervised datasets with the goal of learning mappings between sequences of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " argentina\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " Kingston\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " Steven Tyler\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " three\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " i have a computer i use it all the time i can do anything \n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "flan = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 0.5})\n",
    "\n",
    "llm_test(flan, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of responses:\n",
    "- The model correctly identified the capital of Jamaica and the lead singer of Aerosmith.\n",
    "- However, it provided incorrect answers for the FIFA World Cup winner in 1998 (it was France, not Argentina) and the number of NBA titles won by Michael Jordan (he won six, not three).\n",
    "- The model provides some correct answers but also makes significant errors, particularly in factual questions. This inconsistency suggests it may not be reliable for a RAG application where accuracy is critical.\n",
    "\n",
    "Quality of generated content:\n",
    "- The poem generated by the model is simplistic and lacks the expected structure or creativity typically found in poetry.\n",
    "- The model's ability to generate content is very basic and might not meet the expectations for creative or complex tasks.\n",
    "\n",
    "> Fit for purpose: NO ❌\n",
    ">\n",
    "> Given the errors and simplistic content generation, the FLAN model is not considered fit for the RAG application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOOM\n",
    "\n",
    "- https://huggingface.co/bigscience/bloom\n",
    "\n",
    "BLOOM is an autoregressive Large Language Model (LLM), trained to continue text from a prompt on vast amounts of text data using industrial-scale computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " who won the FIFA World Cup in the year 1998?\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " what is the capital of Jamaica?\"\n",
      "\n",
      "\"Port Royal.\"\n",
      "\n",
      "\"How far is it from Kingston?\"\n",
      "\n",
      "\"About\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " who is the lead singer in Aerosmith?” The response is Steven Tyler.\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " how many NBA titles did Michael Jordan win?”\n",
      "If you want to be able to answer this question, you need to understand what the question\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " write me a four line poem about computers and I will send you a free copy of my book.\"\n",
      "Here's a link to a sample\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "bloom = HuggingFaceHub(repo_id=\"bigscience/bloom\", model_kwargs={\"temperature\": 0.5})\n",
    "\n",
    "llm_test(bloom, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model shows significant issues in processing and responding to queries. The repetition of questions and incomplete answers make it less suitable for tasks where clear and direct responses are needed.\n",
    "\n",
    "> Fit for purpose: NO ❌\n",
    ">\n",
    "> Given the model's current behavior, it doesn't seem fit for a RAG application. It fails to provide reliable, accurate, or even coherent responses, which are essential for such a use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral 7B\n",
    "\n",
    "- https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
    "\n",
    "Mistral 7B is a 7-billion-parameter language model released by Mistral AI. Mistral 7B is a carefully designed language model that provides both efficiency and high performance to enable real-world applications. Due to its efficiency improvements, the model is suitable for real-time applications where quick responses are essential. At the time of its release, Mistral 7B outperformed the best open source 13B model (Llama 2) in all evaluated benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\masso\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " \n",
      "\n",
      "The FIFA World Cup in the year 1998 was won by the French national football team. They defeated Brazil 3–0 in the final match held in Paris, France. This was the second World Cup title for France, and they became the first European team to win the tournament on home soil. The French team was led by star players such as Zinedine Zidane, Didier Deschamps, and Marcel Desailly.\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " \n",
      "\n",
      "Kingston is the capital city of Jamaica. It is located on the southeastern coast of the island and is the largest city in Jamaica. Kingston is known for its vibrant culture, beautiful beaches, and rich history. It is also home to many important institutions, including the University of the West Indies and the Jamaica Stock Exchange. The city has a population of over 600,000 people and is a popular tourist destination.\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " \n",
      "\n",
      "Steven Tyler is the lead singer in Aerosmith. He was born on March 26, 1948, in Yonkers, New York. Tyler is known for his powerful and distinctive voice, as well as his energetic and charismatic stage presence. He has been the lead singer of Aerosmith since the band's formation in 1970. Tyler has also had a successful solo career, releasing several albums and charting several hits on the Billboard charts. He is considered one of the greatest rock vocalists of all time.\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " \n",
      "\n",
      "Michael Jordan won a total of 6 NBA championships during his career with the Chicago Bulls. He won his first championship in 1991, and then went on to win three more in a row from 1992 to 1993, and two more in 1996 and 1997. Jordan is widely regarded as one of the greatest basketball players of all time, and his six championships are a testament to his incredible talent and competitive spirit.\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " \n",
      "\n",
      "In silicon minds, ideas take form,\n",
      "Binary dreams, in endless swarm,\n",
      "Through wires and screens, a world transforms,\n",
      "A dance of data, life's own storm.\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "mistral = HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", \n",
    "                           temperature=0.5,  \n",
    "                           model_kwargs={\"max_length\":64, \"token\":os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")})\n",
    "\n",
    "llm_test(mistral, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of responses:\n",
    "- The model correctly identifies France as the winner of the 1998 FIFA World Cup, including accurate details about the match and players.\n",
    "- It correctly names Kingston as the capital of Jamaica and provides additional relevant information.\n",
    "- Steven Tyler is correctly identified as the lead singer of Aerosmith, with accurate biographical details.\n",
    "- The model accurately states that Michael Jordan won six NBA championships, providing context around his career.\n",
    "\n",
    "Quality of generated content:\n",
    "- The poem about computers is creative, well-structured, and reflects a poetic quality that was missing in the other models.\n",
    "\n",
    "> Fit for purpose: YES ✅\n",
    ">\n",
    "> Based on these results, the Mistral 7B model appears to be well-suited for a RAG application. It provides accurate, detailed responses and generates quality content, making it a strong candidate for our needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI\n",
    "\n",
    "Microsoft Azure, often referred to as Azure is a cloud computing platform run by Microsoft, which offers access, management, and development of applications and services through global data centers. It provides a range of capabilities, including software as a service (SaaS), platform as a service (PaaS), and infrastructure as a service (IaaS). Microsoft Azure supports many programming languages, tools, and frameworks, including Microsoft-specific and third-party software and systems.\n",
    "\n",
    "Azure OpenAI is an Azure service with powerful language models from OpenAI including GPT, Codex and Embeddings model series for content generation, summarization, semantic search, and natural language to code translation.\n",
    "\n",
    "To access AzureOpenAI models you'll need:\n",
    "- Create an Azure account\n",
    "- Create a deployment of an Azure OpenAI model\n",
    "- Get the name and endpoint for your deployment\n",
    "- Create 2 environment variables: AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o\n",
    "\n",
    "- https://platform.openai.com/docs/models/gpt-4o\n",
    "\n",
    "GPT-4o is OpenAI's most advanced model. It is multimodal (accepting text or image inputs and outputting text), and it has the same high intelligence as GPT-4 Turbo but is much more efficient—it generates text 2x faster and is 50% cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai==0.1.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " The FIFA World Cup in 1998 was won by France. The tournament was held in France, and the French national team defeated Brazil 3-0 in the final match held on July 12, 1998, at the Stade de France in Saint-Denis. This victory marked France's first World Cup title.\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " The capital of Jamaica is Kingston.\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " The lead singer of Aerosmith is Steven Tyler. He is known for his distinctive voice, energetic stage presence, and flamboyant style. Tyler has been with the band since its formation in 1970 and has played a significant role in its success over the decades.\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " Michael Jordan won a total of six NBA titles during his career. He achieved this with the Chicago Bulls, securing championships in the years 1991, 1992, 1993, 1996, 1997, and 1998.\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " In circuits vast, where data streams do flow,\n",
      "Silicon minds with endless thoughts aglow,\n",
      "Binary whispers in the night they weave,\n",
      "Crafting realms where human dreams believe.\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "gpt = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    api_version=\"2023-06-01-preview\"\n",
    ")\n",
    "\n",
    "llm_test(gpt, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of responses:\n",
    "- The model correctly identifies France as the winner of the 1998 FIFA World Cup, providing precise details about the event.\n",
    "- It accurately states that Kingston is the capital of Jamaica, delivering a concise response.\n",
    "- Steven Tyler is correctly identified as the lead singer of Aerosmith, with additional relevant context about his career.\n",
    "- The model correctly states that Michael Jordan won six NBA titles and provides the specific years in which these victories occurred.\n",
    "\n",
    "Quality of generated content:\n",
    "- The poem generated by the model is well-crafted, with a good sense of rhythm and imagery. It reflects creativity and an understanding of poetic structure.\n",
    "\n",
    "> Fit for purpose: YES ✅\n",
    ">\n",
    "> Based on these results, the GPT-4o model appears to be very well-suited for a RAG application. It consistently provides accurate and detailed information, along with high-quality generative text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using Google AI:\n",
    "  * Create an API key here: https://aistudio.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-google-genai==1.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI, ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bison\n",
    "\n",
    "- https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/text-bison\n",
    "\n",
    "PaLM 2 large language model that understands and generates language. It's a foundation model that performs well at a variety of natural language tasks such as sentiment analysis, entity extraction, and content creation. The type of content that text-bison can create includes document summaries, answers to questions, and labels that classify content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " France\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " Kingston\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " Steven Tyler\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " 6\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " **Computers**\n",
      "\n",
      "Tools of the modern age,\n",
      "Bringing information to the masses,\n",
      "A constant companion,\n",
      "A window to the world.\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "bison = GoogleGenerativeAI(model=\"models/text-bison-001\", \n",
    "                            temperature=0.5,\n",
    "                            google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "llm_test(bison, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of responses:\n",
    "- The model provides correct and concise answers to factual questions.\n",
    "\n",
    "Quality of generated content:\n",
    "- The poem is simple and direct. It lacks the creative flair or complexity seen in the poems generated by the Mistral 7B and GPT-4o models.\n",
    "\n",
    "> Fit for purpose: NO ❌\n",
    ">\n",
    "> The model delivers accurate answers but tends to be very brief. This could be an advantage in some cases where concise responses are preferred, but it might be limiting in scenarios requiring more detailed information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini Pro\n",
    "\n",
    "- https://ai.google.dev/gemini-api/docs\n",
    "\n",
    "Gemini is a family of generative AI models that lets developers generate content and solve problems. These models are designed and trained to handle both text and images as input. Gemini 1.0 Pro is optimized for natural language tasks, multi-turn text and code chat, and code generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " France won the FIFA World Cup in 1998. \n",
      "\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " The capital of Jamaica is **Kingston**. \n",
      "\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " The lead singer of Aerosmith is **Steven Tyler**. \n",
      "\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " Michael Jordan won **6** NBA titles, all with the Chicago Bulls. \n",
      "\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " Silicon heart, a screen's soft glow,\n",
      "A universe of knowledge, fast or slow.\n",
      "From bits and bytes, worlds come alive,\n",
      "With every click, a new you can thrive. \n",
      "\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", \n",
    "                            temperature=0.5,\n",
    "                            google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "llm_test(gemini, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of responses:\n",
    "- The model delivers accurate responses with a slight emphasis on key details, like mentioning that Michael Jordan won all six titles with the Chicago Bulls. This extra layer of context enhances the quality of its factual responses.\n",
    "\n",
    "Quality of generated content:\n",
    "- The poem is creative and well-crafted.\n",
    "\n",
    "> Fit for purpose: YES ✅\n",
    ">\n",
    "> The Gemini Pro model appears to be highly suitable for a RAG application, offering a good balance between accuracy, detail, and creative generative capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
