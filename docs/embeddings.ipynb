{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research on Embedding Models\n",
    "\n",
    "Vector embeddings is a powerful technique for transforming complex data into numerical forms that can be easily processed and analyzed by machine learning algorithms. It basically allows us to take virtually any data type and represent it as vectors.\n",
    "\n",
    "But it isn't as simple as just turning data into vectors. We want to ensure that we can perform tasks on this transformed data without losing the data's original meaning. For example, if we want to compare two sentences, we don't want just to compare the words they contain but rather whether or not they mean the same thing. \n",
    "\n",
    "To preserve the data's meaning, we need to understand how to produce vectors where relationships between the vectors make sense. To do this, we need what's known as an embedding model. We apply a pre-trained machine learning model that will produce a representation of this data that is more compact while preserving what's meaningful about the data.\n",
    "\n",
    "The goal of embeddings is to capture the semantic meaning or relationships between data points in a way that similar items are close together in the vector space, and dissimilar items are far apart. For example, consider two words \"king\" and \"queen\". An embedding might map these words to vectors such that the difference between the \"king\" and \"queen\" vectors is similar to the difference between the \"man\" and \"woman\" vectors. This reflects the underlying semantic relationships.\n",
    "\n",
    "Key characteristics of embeddings:\n",
    "- Dimensionality: The number of elements in the vector. Higher dimensions can capture more complex relationships but are computationally more expensive.\n",
    "- Similarity: Measured using metrics like cosine similarity or euclidean distance, which help in finding how close or far two vectors are from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv==1.0.1 langchain==0.2.11 langchain-community==0.2.10 scikit-learn==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between vectors.\n",
    "# Values close to 1 indicate very similar vectors, while values close to 0 indicate very different vectors.\n",
    "# Cosine similarity is particularly useful when the magnitude of the vectors is not as important as their direction. \n",
    "# It is often used in text analysis and information retrieval where the orientation (semantic meaning) of vectors \n",
    "# matters more than their magnitude.\n",
    "def compare_embeddings(vector_1, vector_2):\n",
    "    similarity = cosine_similarity([vector_1], [vector_2])\n",
    "    print(f\"Cosine similarity: {similarity[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sentences to test different embedding models\n",
    "sentences_list = [\n",
    "    # Include the same words but have different semantics. Similarity should be low.\n",
    "    [\"I want a new watch for my birthday\", \"I like to watch the TV on weekends\"],      \n",
    "    [\"The bank will close at 5 PM\", \"The river bank is a great place to relax\"],\n",
    "    # Convey the same meaning without sharing words. Similarity should be high.\n",
    "    [\"I have to go to the mechanic\", \"My car is broken\"], \n",
    "    [\"She went to the store to buy some groceries\", \"She went shopping for food\"],\n",
    "    # Completely unrelated in terms of their content and context. Similarity should be low.\n",
    "    [\"The stock market experienced a significant decline last week\", \"She enjoys painting landscapes in her free time\"],\n",
    "    [\"The sun rises in the east every morning\", \"Pizza is a popular food in Italy\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test an embedding model applying it to a set of sentences and analyzing similarity\n",
    "def test_embeddings(model):\n",
    "    for sentences_pair in sentences_list:\n",
    "        vector_1 = model.embed_query(sentences_pair[0])\n",
    "        print(f\"\\\"{sentences_pair[0]}\\\"\")\n",
    "        print(f\" Dimensionality: {len(vector_1)}\")\n",
    "        print(f\" Sample: {vector_1[:5]}\")\n",
    "        print()\n",
    "        \n",
    "        vector_2 = model.embed_query(sentences_pair[1])\n",
    "        print(f\"\\\"{sentences_pair[1]}\\\"\")\n",
    "        print(f\" Dimensionality: {len(vector_2)}\")\n",
    "        print(f\" Sample: {vector_2[:5]}\")\n",
    "        print()\n",
    "\n",
    "        compare_embeddings(vector_1, vector_2)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\masso\\OneDrive\\Escritorio\\rag-chatbot\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I want a new watch for my birthday\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.006526446435600519, -0.05270149186253548, -0.06381335854530334, -0.04306812211871147, 0.04528359696269035]\n",
      "\n",
      "\"I like to watch the TV on weekends\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.021920520812273026, -0.02803944982588291, -0.05818081274628639, 0.006759436335414648, 0.01261313445866108]\n",
      "\n",
      "Cosine similarity: 0.6767452984415877\n",
      "---\n",
      "\"The bank will close at 5 PM\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.019774820655584335, 0.0191058199852705, -0.009512552060186863, -0.06061512976884842, 0.03158271312713623]\n",
      "\n",
      "\"The river bank is a great place to relax\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.028460154309868813, -0.003968124743551016, -0.009560493752360344, -0.02726844884455204, 0.044375017285346985]\n",
      "\n",
      "Cosine similarity: 0.6493495151799284\n",
      "---\n",
      "\"I have to go to the mechanic\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.019688233733177185, -0.04954982548952103, -0.04260384291410446, -0.020591052249073982, -0.012055622413754463]\n",
      "\n",
      "\"My car is broken\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.009147877804934978, 0.0023685169871896505, -0.035380955785512924, -0.03746090829372406, -0.012183723971247673]\n",
      "\n",
      "Cosine similarity: 0.8359565858524703\n",
      "---\n",
      "\"She went to the store to buy some groceries\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.017389267683029175, -0.03367907181382179, -0.0041150725446641445, -0.013308439403772354, 0.027894949540495872]\n",
      "\n",
      "\"She went shopping for food\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.016096636652946472, -0.03155229985713959, -0.020317688584327698, -0.01893610879778862, 0.037719618529081345]\n",
      "\n",
      "Cosine similarity: 0.947891547307478\n",
      "---\n",
      "\"The stock market experienced a significant decline last week\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.0014972486533224583, -0.0037960715126246214, 0.018229085952043533, 0.015960298478603363, 0.041041430085897446]\n",
      "\n",
      "\"She enjoys painting landscapes in her free time\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.05347614362835884, -0.008363157510757446, -0.005584812257438898, -0.04528679698705673, 0.03764292970299721]\n",
      "\n",
      "Cosine similarity: 0.5144232419922934\n",
      "---\n",
      "\"The sun rises in the east every morning\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.00680467439815402, 0.011113613843917847, -0.028659792616963387, -0.026990102604031563, 0.017338844016194344]\n",
      "\n",
      "\"Pizza is a popular food in Italy\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.008190488442778587, -0.024677975103259087, 0.009911262430250645, -0.0019397696014493704, 0.02902967296540737]\n",
      "\n",
      "Cosine similarity: 0.5892190895222624\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "google_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "test_embeddings(google_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_huggingface==0.0.3 huggingface_hub==0.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I want a new watch for my birthday\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.043364789336919785, 0.04182625934481621, -0.0038558896631002426, 0.0431031733751297, 0.01737719029188156]\n",
      "\n",
      "\"I like to watch the TV on weekends\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.04785402491688728, 0.0326734222471714, 0.0009588559623807669, -0.0176838506013155, -0.03530512750148773]\n",
      "\n",
      "Cosine similarity: 0.176958964124023\n",
      "---\n",
      "\"The bank will close at 5 PM\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.04836975410580635, 0.0051988218910992146, -0.029005667194724083, 0.00420030765235424, 0.03131011128425598]\n",
      "\n",
      "\"The river bank is a great place to relax\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.08330544829368591, -0.014301057904958725, -0.029551850631833076, -0.00013575299817603081, -0.01434556394815445]\n",
      "\n",
      "Cosine similarity: 0.23080635655292628\n",
      "---\n",
      "\"I have to go to the mechanic\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.023156633600592613, -0.02565646730363369, -0.012464101426303387, 0.03722125664353371, -0.024508243426680565]\n",
      "\n",
      "\"My car is broken\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.03207498416304588, 0.04779843986034393, -0.025276659056544304, 0.05088168382644653, -0.005267248954623938]\n",
      "\n",
      "Cosine similarity: 0.6053909778607385\n",
      "---\n",
      "\"She went to the store to buy some groceries\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.01857244223356247, 0.02941843494772911, -0.008194404654204845, -0.030242005363106728, 0.04293426126241684]\n",
      "\n",
      "\"She went shopping for food\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.004079811740666628, 0.02301056496798992, -0.019069848582148552, -0.011250101961195469, 0.05938548222184181]\n",
      "\n",
      "Cosine similarity: 0.8859714537130734\n",
      "---\n",
      "\"The stock market experienced a significant decline last week\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.06019498035311699, 0.0500253289937973, -0.04552822932600975, -0.025974158197641373, 0.018337182700634003]\n",
      "\n",
      "\"She enjoys painting landscapes in her free time\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.0283308457583189, 0.05374739691615105, -0.028162294998764992, 0.027542121708393097, 0.007920113392174244]\n",
      "\n",
      "Cosine similarity: -0.09596994000259941\n",
      "---\n",
      "\"The sun rises in the east every morning\"\n",
      " Dimensionality: 768\n",
      " Sample: [0.017762789502739906, 0.04152734950184822, 0.00964907743036747, -0.011952653527259827, -0.023875022307038307]\n",
      "\n",
      "\"Pizza is a popular food in Italy\"\n",
      " Dimensionality: 768\n",
      " Sample: [-0.014318383298814297, 0.07531707733869553, -0.014243819750845432, 0.01029131468385458, 0.02050625905394554]\n",
      "\n",
      "Cosine similarity: 0.1744469439305314\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "\n",
    "hface_embeddings = HuggingFaceEndpointEmbeddings()\n",
    "\n",
    "test_embeddings(hface_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai==0.1.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I want a new watch for my birthday\"\n",
      " Dimensionality: 1536\n",
      " Sample: [-0.030059291049838066, 0.0008972808718681335, 7.123553223209456e-05, -0.03169933333992958, -0.027586987242102623]\n",
      "\n",
      "\"I like to watch the TV on weekends\"\n",
      " Dimensionality: 1536\n",
      " Sample: [-0.008290333673357964, -0.013153238222002983, 0.011332020163536072, -0.024978503584861755, -0.02726767398416996]\n",
      "\n",
      "Cosine similarity: 0.785458414824596\n",
      "---\n",
      "\"The bank will close at 5 PM\"\n",
      " Dimensionality: 1536\n",
      " Sample: [-0.030440565198659897, -0.0058855642564594746, 0.014171946793794632, -0.009836236946284771, -0.0347115620970726]\n",
      "\n",
      "\"The river bank is a great place to relax\"\n",
      " Dimensionality: 1536\n",
      " Sample: [0.010515332221984863, 0.00823382381349802, 0.013548845425248146, 0.0017079447861760855, -0.03066653199493885]\n",
      "\n",
      "Cosine similarity: 0.7972961835284542\n",
      "---\n",
      "\"I have to go to the mechanic\"\n",
      " Dimensionality: 1536\n",
      " Sample: [-0.013156797736883163, 0.009770764969289303, 0.0030002621933817863, -0.014506213366985321, -0.03778362646698952]\n",
      "\n",
      "\"My car is broken\"\n",
      " Dimensionality: 1536\n",
      " Sample: [-0.02931201085448265, 0.00582078006118536, -0.0009278247598558664, -0.011004616506397724, -0.04177339747548103]\n",
      "\n",
      "Cosine similarity: 0.8835356353679278\n",
      "---\n",
      "\"She went to the store to buy some groceries\"\n",
      " Dimensionality: 1536\n",
      " Sample: [0.014651336707174778, -0.008842818439006805, 0.009468256495893002, -0.0062234122306108475, -0.02312260866165161]\n",
      "\n",
      "\"She went shopping for food\"\n",
      " Dimensionality: 1536\n",
      " Sample: [0.005082108546048403, -0.009029285982251167, 0.004693347495049238, -0.0005396409542299807, -0.0193628016859293]\n",
      "\n",
      "Cosine similarity: 0.9581197711510169\n",
      "---\n",
      "\"The stock market experienced a significant decline last week\"\n",
      " Dimensionality: 1536\n",
      " Sample: [-0.030045846477150917, -0.013299818150699139, 0.019426412880420685, -0.005552227143198252, -0.022106798365712166]\n",
      "\n",
      "\"She enjoys painting landscapes in her free time\"\n",
      " Dimensionality: 1536\n",
      " Sample: [0.00992916151881218, 0.014008779078722, 0.01518873032182455, -0.023071806877851486, -0.021967172622680664]\n",
      "\n",
      "Cosine similarity: 0.7156932697442453\n",
      "---\n",
      "\"The sun rises in the east every morning\"\n",
      " Dimensionality: 1536\n",
      " Sample: [0.025747857987880707, -0.010837619192898273, -0.009141727350652218, -0.0020022671669721603, -0.011338960379362106]\n",
      "\n",
      "\"Pizza is a popular food in Italy\"\n",
      " Dimensionality: 1536\n",
      " Sample: [0.03468665853142738, -0.021228525787591934, 0.00017003450193442404, -0.024102842435240746, -0.013592102564871311]\n",
      "\n",
      "Cosine similarity: 0.7488880268565167\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "openai_embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"ada-002\",\n",
    "    openai_api_version=\"2024-06-01\"\n",
    ")\n",
    "\n",
    "test_embeddings(openai_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Embedding model | Sentence 1 | Sentence 2 | Cosine similarity \n",
    ":---: | :---: | :---: | :---:\n",
    "Google | \"I want a new watch for my birthday\" | \"I like to watch the TV on weekends\" | 0.67\n",
    "Google | \"The bank will close at 5 PM\" | \"The river bank is a great place to relax\" | 0.65\n",
    "Google | \"I have to go to the mechanic\" | \"My car is broken\" | 0.84\n",
    "Google | \"She went to the store to buy some groceries\" | \"She went shopping for food\" | 0.95\n",
    "Google | \"The stock market experienced a significant decline last week\" | \"She enjoys painting landscapes in her free time\" | 0.52\n",
    "Google | \"The sun rises in the east every morning\" | \"Pizza is a popular food in Italy\" | 0.59\n",
    "Hugging Face | \"I want a new watch for my birthday\" | \"I like to watch the TV on weekends\" | 0.17\n",
    "Hugging Face | \"The bank will close at 5 PM\" | \"The river bank is a great place to relax\" | 0.23\n",
    "Hugging Face | \"I have to go to the mechanic\" | \"My car is broken\" | 0.60\n",
    "Hugging Face | \"She went to the store to buy some groceries\" | \"She went shopping for food\" | 0.88\n",
    "Hugging Face | \"The stock market experienced a significant decline last week\" | \"She enjoys painting landscapes in her free time\" | -0.09\n",
    "Hugging Face | \"The sun rises in the east every morning\" | \"Pizza is a popular food in Italy\" | 0.17\n",
    "OpenAI | \"I want a new watch for my birthday\" | \"I like to watch the TV on weekends\" | 0.78\n",
    "OpenAI | \"The bank will close at 5 PM\" | \"The river bank is a great place to relax\" | 0.79\n",
    "OpenAI | \"I have to go to the mechanic\" | \"My car is broken\" | 0.88\n",
    "OpenAI | \"She went to the store to buy some groceries\" | \"She went shopping for food\" | 0.96\n",
    "OpenAI | \"The stock market experienced a significant decline last week\" | \"She enjoys painting landscapes in her free time\" | 0.72\n",
    "OpenAI | \"The sun rises in the east every morning\" | \"Pizza is a popular food in Italy\" | 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- The OpenAI embedding model appears to be the most effective at capturing semantic similarity overall, making it a strong candidate for the RAG application.\n",
    "- The Google embedding model is a solid alternative, with reasonable performance across various sentence pairs.\n",
    "- The Hugging Face embedding model may not be the best fit for our application, as it struggles with semantic differentiation in key scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
