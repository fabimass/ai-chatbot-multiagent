{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM models test\n",
    "\n",
    "As part of my initial investigation, I want to try different LLM models to find out which is the best option for the specialized chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv==1.0.1 ipywidgets==8.1.2 langchain==0.2.1 langchain-community==0.2.1 langchain-huggingface==0.0.3 langchain-google-genai==1.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"who won the FIFA World Cup in the year 1998?\", \n",
    "             \"what is the capital of Jamaica?\", \n",
    "             \"who is the lead singer in Aerosmith?\",\n",
    "             \"how many NBA titles did Michael Jordan win?\",\n",
    "             \"write me a four line poem about computers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_test(llm, prompt_list):\n",
    "    print(\"-----\")\n",
    "    for prompt in prompt_list:\n",
    "        print(f\"{prompt}\\n {llm.predict(prompt)}\\n\")\n",
    "        print(\"-----\")\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using Hugging Face:\n",
    "  * Create an access token here: https://huggingface.co/settings/tokens\n",
    "  * Create an environment variable called: HUGGINGFACEHUB_API_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain_huggingface.llms import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLAN\n",
    "\n",
    "- https://huggingface.co/google/flan-t5-large\n",
    "- https://research.google/blog/introducing-flan-more-generalizable-language-models-with-instruction-fine-tuning/\n",
    "\n",
    "Flan-T5 is an open-source LLM that’s available for commercial usage. Published by Google researchers, Flan-T5 is an encoder-decoder model pre-trained on a variety of language tasks. The model has been trained on supervised and unsupervised datasets with the goal of learning mappings between sequences of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " argentina\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " Kingston\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " Steven Tyler\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " three\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " i have a computer i use it all the time i can do anything \n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "flan = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 0.5})\n",
    "\n",
    "llm_test(flan, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit for purpose: NO ❌\n",
    "\n",
    "- Answers are pretty simple and lack verbosity.\n",
    "- Some answers are wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOOM\n",
    "\n",
    "- https://huggingface.co/bigscience/bloom\n",
    "\n",
    "BLOOM is an autoregressive Large Language Model (LLM), trained to continue text from a prompt on vast amounts of text data using industrial-scale computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " who won the FIFA World Cup in the year 1998?\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " what is the capital of Jamaica?\"\n",
      "\n",
      "\"Port Royal.\"\n",
      "\n",
      "\"How far is it from Kingston?\"\n",
      "\n",
      "\"About\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " who is the lead singer in Aerosmith?” The response is Steven Tyler.\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " how many NBA titles did Michael Jordan win?”\n",
      "If you want to be able to answer this question, you need to understand what the question\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " write me a four line poem about computers and I will send you a free copy of my book.\"\n",
      "Here's a link to a sample\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "bloom = HuggingFaceHub(repo_id=\"bigscience/bloom\", model_kwargs={\"temperature\": 0.5})\n",
    "\n",
    "llm_test(bloom, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit for purpose: NO ❌\n",
    "\n",
    "- This model is not suited for answering questions, it's more fore generating text afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral 7B\n",
    "\n",
    "- https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
    "- https://mistral.ai/news/announcing-mistral-7b/\n",
    "\n",
    "Mistral 7B is a 7-billion-parameter language model released by Mistral AI. Mistral 7B is a carefully designed language model that provides both efficiency and high performance to enable real-world applications. Due to its efficiency improvements, the model is suitable for real-time applications where quick responses are essential. At the time of its release, Mistral 7B outperformed the best open source 13B model (Llama 2) in all evaluated benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\masso\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " \n",
      "\n",
      "The FIFA World Cup in the year 1998 was won by the French national football team. They defeated Brazil 3–0 in the final match held in Paris, France. This was the second World Cup title for France, and they became the first European team to win the tournament on home soil. The French team was led by star players such as Zinedine Zidane, Didier Deschamps, and Marcel Desailly.\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " \n",
      "\n",
      "Kingston is the capital city of Jamaica. It is located on the southeastern coast of the island and is the largest city in Jamaica. Kingston is known for its vibrant culture, beautiful beaches, and rich history. It is also home to many important institutions, including the University of the West Indies and the Jamaica Stock Exchange. The city has a population of over 600,000 people and is a popular tourist destination.\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " \n",
      "\n",
      "Steven Tyler is the lead singer in Aerosmith. He was born on March 26, 1948, in Yonkers, New York. Tyler is known for his powerful and distinctive voice, as well as his energetic and charismatic stage presence. He has been the lead singer of Aerosmith since the band's formation in 1970. Tyler has also had a successful solo career, releasing several albums and charting several hits on the Billboard charts. He is considered one of the greatest rock vocalists of all time.\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " \n",
      "\n",
      "Michael Jordan won a total of 6 NBA championships during his career with the Chicago Bulls. He won his first championship in 1991, and then went on to win three more in a row from 1992 to 1993, and two more in 1996 and 1997. Jordan is widely regarded as one of the greatest basketball players of all time, and his six championships are a testament to his incredible talent and competitive spirit.\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " \n",
      "\n",
      "In silicon minds, ideas take form,\n",
      "Binary dreams, in endless swarm,\n",
      "Through wires and screens, a world transforms,\n",
      "A dance of data, life's own storm.\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "mistral = HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", \n",
    "                           temperature=0.5,  \n",
    "                           model_kwargs={\"max_length\":64, \"token\":os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")})\n",
    "\n",
    "llm_test(mistral, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit for purpose: YES ✅\n",
    "\n",
    "- Responses are correct and with good verbosity.\n",
    "- It's fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 3.5\n",
    "\n",
    "- https://platform.openai.com/docs/models/gpt-3-5-turbo\n",
    "\n",
    "GPT-3.5 Turbo models can understand and generate natural language or code and have been optimized for chat.\n",
    "\n",
    "<br>\n",
    "\n",
    "Fit for purpose: NO ❌\n",
    "\n",
    "- At the time of this research, OpenAI is no longer giving any credits to pay for use simply for those that sign up. You need to prepay for credits in order to use the API services, which are billed by the amount of language data used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using Google AI:\n",
    "  * Create an API key here: https://aistudio.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bison\n",
    "\n",
    "- https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/text-bison\n",
    "\n",
    "PaLM 2 large language model that understands and generates language. It's a foundation model that performs well at a variety of natural language tasks such as sentiment analysis, entity extraction, and content creation. The type of content that text-bison can create includes document summaries, answers to questions, and labels that classify content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " France\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " Kingston\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " Steven Tyler\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " 6\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " **Computers**\n",
      "\n",
      "Tools of the modern age,\n",
      "Bringing information to the masses,\n",
      "A constant companion,\n",
      "A window to the world.\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "bison = GoogleGenerativeAI(model=\"models/text-bison-001\", \n",
    "                            temperature=0.5,\n",
    "                            google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "llm_test(bison, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit for purpose: YES ✅\n",
    "\n",
    "- Responses are correct.\n",
    "- Not very verbose, stright to the point.\n",
    "- Faster than Gemini Pro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini Pro\n",
    "\n",
    "- https://ai.google.dev/gemini-api/docs\n",
    "\n",
    "Gemini is a family of generative AI models that lets developers generate content and solve problems. These models are designed and trained to handle both text and images as input. Gemini 1.0 Pro is optimized for natural language tasks, multi-turn text and code chat, and code generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "who won the FIFA World Cup in the year 1998?\n",
      " France won the FIFA World Cup in 1998. \n",
      "\n",
      "\n",
      "-----\n",
      "what is the capital of Jamaica?\n",
      " The capital of Jamaica is **Kingston**. \n",
      "\n",
      "\n",
      "-----\n",
      "who is the lead singer in Aerosmith?\n",
      " The lead singer of Aerosmith is **Steven Tyler**. \n",
      "\n",
      "\n",
      "-----\n",
      "how many NBA titles did Michael Jordan win?\n",
      " Michael Jordan won **6** NBA titles, all with the Chicago Bulls. \n",
      "\n",
      "\n",
      "-----\n",
      "write me a four line poem about computers\n",
      " Silicon heart, a screen's soft glow,\n",
      "A universe of knowledge, fast or slow.\n",
      "From bits and bytes, worlds come alive,\n",
      "With every click, a new you can thrive. \n",
      "\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", \n",
    "                            temperature=0.5,\n",
    "                            google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "llm_test(gemini, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit for purpose: YES ✅\n",
    "\n",
    "- Responses are correct and with good verbosity.\n",
    "- Not much difference with Bison, a bit more verbose.\n",
    "- It's a bit slower than Mistral and shows less verbosity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
